{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch (fp32) -> ONNX (fp32) -> ONNX (QDQ/QOp) -> TVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://pytorch.org/docs/stable/quantization.html#quantization-api-reference\n",
    "* https://pytorch.org/tutorials/recipes/quantization.html\n",
    "* https://tvm.apache.org/docs/how_to/compile_models/from_pytorch.html\n",
    "* https://tvm.apache.org/docs/how_to/deploy_models/deploy_prequantized.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# for dataset\n",
    "dataset_root = \"/datasets/IMAGENET\"\n",
    "dataset_samples = 1000\n",
    "dataset_seed = 0\n",
    "batch_size = 32\n",
    "\n",
    "# for model\n",
    "model_name = \"resnet18\"\n",
    "weight_name = \"ResNet18_Weights.DEFAULT\"\n",
    "input_name = \"input\"\n",
    "height = 224\n",
    "width = 224\n",
    "\n",
    "# for onnx export\n",
    "opset_version = 13\n",
    "\n",
    "# for onnxruntime quantization\n",
    "calib_samples = 256\n",
    "quant_format = \"QOperator\"  #  [\"Operator\", \"ODQ\"]\n",
    "activation_type = \"QUInt8\"  #  [\"QInt8\", \"QUInt8\"]\n",
    "activation_symmetric = False  #  [True, False]\n",
    "weight_type = \"QInt8\"  #  [\"QInt8\", \"QUInt8\"]\n",
    "weight_symmetric = True  #  [True, False]\n",
    "per_channel = False  #  [True, False]\n",
    "calibrate_method_str = \"MinMax\"  #  [\"MinMax\", \"Entropy\", \"Percentile\"]\n",
    "\n",
    "# for TVM\n",
    "tvm_target = 'llvm'\n",
    "dataset_samples_on_tvm = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import torch\n",
    "import torchvision\n",
    "from onnxruntime.quantization.registry import QLinearOpsRegistry\n",
    "\n",
    "import onnx_util\n",
    "import torch_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Setting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Make artifact directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_dir_name = \"-\".join(\n",
    "    [\n",
    "        f\"model_name={model_name}\",\n",
    "        f\"quant_format={quant_format}\",\n",
    "        f\"per_channel={per_channel}\",\n",
    "        f\"activation_type={activation_type}\",\n",
    "        f\"activation_symmetric={activation_symmetric}\"\n",
    "        f\"weight_type={weight_type}\",\n",
    "        f\"weight_symmetric={weight_symmetric}\"\n",
    "        f\"calib={calibrate_method_str}\",\n",
    "    ]\n",
    ")\n",
    "artifact_dir = pathlib.Path().cwd().resolve() / \"artifacts\" / artifact_dir_name\n",
    "os.makedirs(artifact_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Prepare float32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizableResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): QuantizableBasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (add_relu): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizableBasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (add_relu): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): QuantizableBasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (add_relu): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizableBasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (add_relu): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): QuantizableBasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (add_relu): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizableBasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (add_relu): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): QuantizableBasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (add_relu): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizableBasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (add_relu): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "weights = torchvision.models.get_weight(weight_name)\n",
    "model = getattr(torchvision.models.quantization, model_name)(weights=weights).eval()\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageNet(\n",
    "    dataset_root,\n",
    "    split=\"val\",\n",
    "    transform=preprocess,\n",
    ")\n",
    "dataset = torch_util.subset_dataset(\n",
    "    dataset=dataset,\n",
    "    num_samples=dataset_samples,\n",
    "    seed=dataset_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Test float32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test 1000 img]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:25<00:00,  1.27it/s, Top1=tensor(69.9219), Top5=tensor(89.7461)]\n"
     ]
    }
   ],
   "source": [
    "torch_util.test_torch(model, dataset, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Export to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, height, width, requires_grad=True)\n",
    "\n",
    "onnx_model_file_path = str(artifact_dir / \"fp32.onnx\")\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    onnx_model_file_path,\n",
    "    export_params=True,\n",
    "    opset_version=opset_version,\n",
    "    do_constant_folding=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Test ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test 1000 img]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:05<00:00, 15.24it/s, Top1=tensor(69.5000), Top5=tensor(89.5000)]\n"
     ]
    }
   ],
   "source": [
    "session_fp32 = onnxruntime.InferenceSession(onnx_model_file_path)\n",
    "onnx_util.test_onnx(session_fp32, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Static Quantization on ONNXRuntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Define DataReader for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataReader(onnxruntime.quantization.CalibrationDataReader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: torchvision.datasets.VisionDataset,\n",
    "        batch_size: int = 1,\n",
    "    ):\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)\n",
    "        self.dataiter = self.dataloader.__iter__()\n",
    "\n",
    "    def get_next(self):\n",
    "        out = next(self.dataiter, None)\n",
    "        if out is None:\n",
    "            return None\n",
    "\n",
    "        image, _ = out\n",
    "        return {\"input\": image.numpy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Static Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_calib = torch_util.subset_dataset(dataset, calib_samples, seed=dataset_seed)\n",
    "dr = ImageNetDataReader(dataset)\n",
    "\n",
    "# Exclude gemm from quantization because it cannot be parse by TVM\n",
    "op_types_to_quantize = list(QLinearOpsRegistry.keys())\n",
    "op_types_to_quantize.remove(\"Gemm\")\n",
    "\n",
    "calibrate_method = onnx_util.calibration_method_from_str(calibrate_method_str)\n",
    "\n",
    "quant_onnx_model_file_path = str(artifact_dir / \"quant.onnx\")\n",
    "\n",
    "onnxruntime.quantization.quantize_static(\n",
    "    model_input=onnx_model_file_path,\n",
    "    model_output=quant_onnx_model_file_path,\n",
    "    calibration_data_reader=dr,\n",
    "    quant_format=onnxruntime.quantization.QuantFormat.from_string(quant_format),\n",
    "    op_types_to_quantize=op_types_to_quantize,\n",
    "    per_channel=per_channel,\n",
    "    activation_type=onnxruntime.quantization.QuantType.from_string(activation_type),\n",
    "    weight_type=onnxruntime.quantization.QuantType.from_string(weight_type),\n",
    "    calibrate_method=calibrate_method,\n",
    "    extra_options={\n",
    "        \"ActivationSymmetric\": activation_symmetric,\n",
    "        \"WeightSymmetric\": weight_symmetric,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Test Quantized ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test 1000 img]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:46<00:00, 21.36it/s, Top1=tensor(70.6000), Top5=tensor(89.8000)]\n"
     ]
    }
   ],
   "source": [
    "session_quant = onnxruntime.InferenceSession(quant_onnx_model_file_path)\n",
    "onnx_util.test_onnx(session_quant, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compile by TVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Load quantized ONNX model to relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%input: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = qnn.quantize(%input, 0.0186584f /* ty=float32 */, 114 /* ty=int32 */, out_dtype=\"uint8\", axis=1) /* ty=Tensor[(1, 3, 224, 224), uint8] */;\n",
      "  %1 = qnn.conv2d(%0, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), int8] */, 114 /* ty=int32 */, 0 /* ty=int32 */, 0.0186584f /* ty=float32 */, 0.00310138f /* ty=float32 */, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 112, 112), int32] */;\n",
      "  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 112, 112), int32] */;\n",
      "  %3 = qnn.requantize(%2, 5.7867e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0271661f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 112, 112), uint8] */;\n",
      "  %4 = nn.max_pool2d(%3, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %5 = qnn.conv2d(%4, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0271661f /* ty=float32 */, 0.00294885f /* ty=float32 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %6 = nn.bias_add(%5, meta[relay.Constant][3] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %7 = qnn.requantize(%6, 8.01088e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0178673f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %8 = qnn.conv2d(%7, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0178673f /* ty=float32 */, 0.00606914f /* ty=float32 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %9 = nn.bias_add(%8, meta[relay.Constant][5] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %10 = qnn.requantize(%9, 0.000108439f /* ty=float32 */, 0 /* ty=int32 */, 0.0469651f /* ty=float32 */, 144 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %11 = qnn.dequantize(%10, 0.0469651f /* ty=float32 */, 144 /* ty=int32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %12 = qnn.dequantize(%4, 0.0271661f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %13 = add(%11, %12) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %14 = qnn.quantize(%13, 0.0328644f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %15 = qnn.conv2d(%14, meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0328644f /* ty=float32 */, 0.00220439f /* ty=float32 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %16 = nn.bias_add(%15, meta[relay.Constant][7] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %17 = qnn.requantize(%16, 7.2446e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0152436f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %18 = qnn.conv2d(%17, meta[relay.Constant][8] /* ty=Tensor[(64, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0152436f /* ty=float32 */, 0.00824717f /* ty=float32 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %19 = nn.bias_add(%18, meta[relay.Constant][9] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %20 = qnn.requantize(%19, 0.000125717f /* ty=float32 */, 0 /* ty=int32 */, 0.0619377f /* ty=float32 */, 153 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %21 = qnn.dequantize(%20, 0.0619377f /* ty=float32 */, 153 /* ty=int32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %22 = qnn.dequantize(%14, 0.0328644f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %23 = add(%21, %22) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %24 = qnn.quantize(%23, 0.0361272f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %25 = qnn.conv2d(%24, meta[relay.Constant][10] /* ty=Tensor[(128, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0361272f /* ty=float32 */, 0.00167477f /* ty=float32 */, strides=[2, 2], padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %26 = nn.bias_add(%25, meta[relay.Constant][11] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %27 = qnn.requantize(%26, 6.05048e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0149092f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %28 = qnn.conv2d(%27, meta[relay.Constant][12] /* ty=Tensor[(128, 128, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0149092f /* ty=float32 */, 0.00570197f /* ty=float32 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %29 = nn.bias_add(%28, meta[relay.Constant][13] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %30 = qnn.requantize(%29, 8.50116e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0455358f /* ty=float32 */, 89 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %31 = qnn.conv2d(%24, meta[relay.Constant][14] /* ty=Tensor[(128, 64, 1, 1), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0361272f /* ty=float32 */, 0.00545079f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %32 = nn.bias_add(%31, meta[relay.Constant][15] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %33 = qnn.requantize(%32, 0.000196922f /* ty=float32 */, 0 /* ty=int32 */, 0.0377357f /* ty=float32 */, 147 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %34 = qnn.dequantize(%30, 0.0455358f /* ty=float32 */, 89 /* ty=int32 */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %35 = qnn.dequantize(%33, 0.0377357f /* ty=float32 */, 147 /* ty=int32 */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %36 = add(%34, %35) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %37 = qnn.quantize(%36, 0.0339082f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %38 = qnn.conv2d(%37, meta[relay.Constant][16] /* ty=Tensor[(128, 128, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0339082f /* ty=float32 */, 0.00244922f /* ty=float32 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %39 = nn.bias_add(%38, meta[relay.Constant][17] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %40 = qnn.requantize(%39, 8.30486e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0178987f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %41 = qnn.conv2d(%40, meta[relay.Constant][18] /* ty=Tensor[(128, 128, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0178987f /* ty=float32 */, 0.00690613f /* ty=float32 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %42 = nn.bias_add(%41, meta[relay.Constant][19] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %43 = qnn.requantize(%42, 0.000123611f /* ty=float32 */, 0 /* ty=int32 */, 0.0503514f /* ty=float32 */, 155 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %44 = qnn.dequantize(%43, 0.0503514f /* ty=float32 */, 155 /* ty=int32 */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %45 = qnn.dequantize(%37, 0.0339082f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %46 = add(%44, %45) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %47 = qnn.quantize(%46, 0.028905f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %48 = qnn.conv2d(%47, meta[relay.Constant][20] /* ty=Tensor[(256, 128, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.028905f /* ty=float32 */, 0.00185604f /* ty=float32 */, strides=[2, 2], padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %49 = nn.bias_add(%48, meta[relay.Constant][21] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %50 = qnn.requantize(%49, 5.3649e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0147711f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %51 = qnn.conv2d(%50, meta[relay.Constant][22] /* ty=Tensor[(256, 256, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0147711f /* ty=float32 */, 0.00444031f /* ty=float32 */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %52 = nn.bias_add(%51, meta[relay.Constant][23] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %53 = qnn.requantize(%52, 6.55884e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.04072f /* ty=float32 */, 102 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %54 = qnn.conv2d(%47, meta[relay.Constant][24] /* ty=Tensor[(256, 128, 1, 1), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.028905f /* ty=float32 */, 0.00321387f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %55 = nn.bias_add(%54, meta[relay.Constant][25] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %56 = qnn.requantize(%55, 9.2897e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0160918f /* ty=float32 */, 156 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %57 = qnn.dequantize(%53, 0.04072f /* ty=float32 */, 102 /* ty=int32 */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %58 = qnn.dequantize(%56, 0.0160918f /* ty=float32 */, 156 /* ty=int32 */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %59 = add(%57, %58) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %60 = qnn.quantize(%59, 0.0217659f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %61 = qnn.conv2d(%60, meta[relay.Constant][26] /* ty=Tensor[(256, 256, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0217659f /* ty=float32 */, 0.00214475f /* ty=float32 */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %62 = nn.bias_add(%61, meta[relay.Constant][27] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %63 = qnn.requantize(%62, 4.66825e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0174921f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %64 = qnn.conv2d(%63, meta[relay.Constant][28] /* ty=Tensor[(256, 256, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0174921f /* ty=float32 */, 0.00763875f /* ty=float32 */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %65 = nn.bias_add(%64, meta[relay.Constant][29] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %66 = qnn.requantize(%65, 0.000133618f /* ty=float32 */, 0 /* ty=int32 */, 0.0529469f /* ty=float32 */, 164 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %67 = qnn.dequantize(%66, 0.0529469f /* ty=float32 */, 164 /* ty=int32 */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %68 = qnn.dequantize(%60, 0.0217659f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %69 = add(%67, %68) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %70 = qnn.quantize(%69, 0.0367017f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %71 = qnn.conv2d(%70, meta[relay.Constant][30] /* ty=Tensor[(512, 256, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0367017f /* ty=float32 */, 0.00237498f /* ty=float32 */, strides=[2, 2], padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %72 = nn.bias_add(%71, meta[relay.Constant][31] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %73 = qnn.requantize(%72, 8.71658e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0136074f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %74 = qnn.conv2d(%73, meta[relay.Constant][32] /* ty=Tensor[(512, 512, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0136074f /* ty=float32 */, 0.0090061f /* ty=float32 */, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %75 = nn.bias_add(%74, meta[relay.Constant][33] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %76 = qnn.requantize(%75, 0.00012255f /* ty=float32 */, 0 /* ty=int32 */, 0.0484018f /* ty=float32 */, 114 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %77 = qnn.conv2d(%70, meta[relay.Constant][34] /* ty=Tensor[(512, 256, 1, 1), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0367017f /* ty=float32 */, 0.00785991f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %78 = nn.bias_add(%77, meta[relay.Constant][35] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %79 = qnn.requantize(%78, 0.000288472f /* ty=float32 */, 0 /* ty=int32 */, 0.0285382f /* ty=float32 */, 115 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %80 = qnn.dequantize(%76, 0.0484018f /* ty=float32 */, 114 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %81 = qnn.dequantize(%79, 0.0285382f /* ty=float32 */, 115 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %82 = add(%80, %81) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %83 = qnn.quantize(%82, 0.0334308f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %84 = qnn.conv2d(%83, meta[relay.Constant][36] /* ty=Tensor[(512, 512, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0334308f /* ty=float32 */, 0.00230916f /* ty=float32 */, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %85 = nn.bias_add(%84, meta[relay.Constant][37] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %86 = qnn.requantize(%85, 7.7197e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0133824f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %87 = qnn.conv2d(%86, meta[relay.Constant][38] /* ty=Tensor[(512, 512, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0133824f /* ty=float32 */, 0.0287268f /* ty=float32 */, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %88 = nn.bias_add(%87, meta[relay.Constant][39] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %89 = qnn.requantize(%88, 0.000384433f /* ty=float32 */, 0 /* ty=int32 */, 0.225387f /* ty=float32 */, 68 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %90 = qnn.dequantize(%89, 0.225387f /* ty=float32 */, 68 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %91 = qnn.dequantize(%83, 0.0334308f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %92 = add(%90, %91) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %93 = qnn.quantize(%92, 0.165314f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %94 = qnn.dequantize(%93, 0.165314f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %95 = nn.global_avg_pool2d(%94) /* ty=Tensor[(1, 512, 1, 1), float32] */;\n",
      "  %96 = qnn.quantize(%95, 0.0553716f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 1, 1), uint8] */;\n",
      "  %97 = qnn.dequantize(%96, 0.0553716f /* ty=float32 */, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 512, 1, 1), float32] */;\n",
      "  %98 = nn.batch_flatten(%97) /* ty=Tensor[(1, 512), float32] */;\n",
      "  %99 = nn.dense(%98, meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */, units=1000) /* ty=Tensor[(1, 1000), float32] */;\n",
      "  add(%99, meta[relay.Constant][41] /* ty=Tensor[(1000), float32] */) /* ty=Tensor[(1, 1000), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "onnx_model = onnx.load(quant_onnx_model_file_path)\n",
    "\n",
    "input_shapes = {'input': (1, 3, height, width)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, input_shapes)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%input: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = qnn.quantize(%input, 0.0186584f /* ty=float32 */, 114 /* ty=int32 */, out_dtype=\"uint8\", axis=1) /* ty=Tensor[(1, 3, 224, 224), uint8] */;\n",
      "  %1 = qnn.conv2d(%0, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), int8] */, 114 /* ty=int32 */, 0 /* ty=int32 */, 0.0186584f /* ty=float32 */, 0.00310138f /* ty=float32 */, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 112, 112), int32] */;\n",
      "  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 112, 112), int32] */;\n",
      "  %3 = qnn.requantize(%2, 5.7867e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0271661f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 112, 112), uint8] */;\n",
      "  %4 = nn.max_pool2d(%3, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %5 = qnn.conv2d(%4, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0271661f /* ty=float32 */, 0.00294885f /* ty=float32 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %6 = nn.bias_add(%5, meta[relay.Constant][3] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %7 = qnn.requantize(%6, 8.01088e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0178673f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %8 = qnn.conv2d(%7, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0178673f /* ty=float32 */, 0.00606914f /* ty=float32 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %9 = nn.bias_add(%8, meta[relay.Constant][5] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %10 = qnn.requantize(%9, 0.000108439f /* ty=float32 */, 0 /* ty=int32 */, 0.0469651f /* ty=float32 */, 144 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %11 = qnn.dequantize(%10, 0.0469651f /* ty=float32 */, 144 /* ty=int32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %12 = qnn.dequantize(%4, 0.0271661f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %13 = add(%11, %12) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %14 = qnn.quantize(%13, 0.0328644f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %15 = qnn.conv2d(%14, meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0328644f /* ty=float32 */, 0.00220439f /* ty=float32 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %16 = nn.bias_add(%15, meta[relay.Constant][7] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %17 = qnn.requantize(%16, 7.2446e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0152436f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %18 = qnn.conv2d(%17, meta[relay.Constant][8] /* ty=Tensor[(64, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0152436f /* ty=float32 */, 0.00824717f /* ty=float32 */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %19 = nn.bias_add(%18, meta[relay.Constant][9] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
      "  %20 = qnn.requantize(%19, 0.000125717f /* ty=float32 */, 0 /* ty=int32 */, 0.0619377f /* ty=float32 */, 153 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %21 = qnn.dequantize(%20, 0.0619377f /* ty=float32 */, 153 /* ty=int32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %22 = qnn.dequantize(%14, 0.0328644f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %23 = add(%21, %22) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %24 = qnn.quantize(%23, 0.0361272f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 64, 56, 56), uint8] */;\n",
      "  %25 = qnn.conv2d(%24, meta[relay.Constant][10] /* ty=Tensor[(128, 64, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0361272f /* ty=float32 */, 0.00167477f /* ty=float32 */, strides=[2, 2], padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %26 = nn.bias_add(%25, meta[relay.Constant][11] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %27 = qnn.requantize(%26, 6.05048e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0149092f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %28 = qnn.conv2d(%27, meta[relay.Constant][12] /* ty=Tensor[(128, 128, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0149092f /* ty=float32 */, 0.00570197f /* ty=float32 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %29 = nn.bias_add(%28, meta[relay.Constant][13] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %30 = qnn.requantize(%29, 8.50116e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0455358f /* ty=float32 */, 89 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %31 = qnn.conv2d(%24, meta[relay.Constant][14] /* ty=Tensor[(128, 64, 1, 1), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0361272f /* ty=float32 */, 0.00545079f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %32 = nn.bias_add(%31, meta[relay.Constant][15] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %33 = qnn.requantize(%32, 0.000196922f /* ty=float32 */, 0 /* ty=int32 */, 0.0377357f /* ty=float32 */, 147 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %34 = qnn.dequantize(%30, 0.0455358f /* ty=float32 */, 89 /* ty=int32 */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %35 = qnn.dequantize(%33, 0.0377357f /* ty=float32 */, 147 /* ty=int32 */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %36 = add(%34, %35) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %37 = qnn.quantize(%36, 0.0339082f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %38 = qnn.conv2d(%37, meta[relay.Constant][16] /* ty=Tensor[(128, 128, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0339082f /* ty=float32 */, 0.00244922f /* ty=float32 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %39 = nn.bias_add(%38, meta[relay.Constant][17] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %40 = qnn.requantize(%39, 8.30486e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0178987f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %41 = qnn.conv2d(%40, meta[relay.Constant][18] /* ty=Tensor[(128, 128, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0178987f /* ty=float32 */, 0.00690613f /* ty=float32 */, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %42 = nn.bias_add(%41, meta[relay.Constant][19] /* ty=Tensor[(128), int32] */) /* ty=Tensor[(1, 128, 28, 28), int32] */;\n",
      "  %43 = qnn.requantize(%42, 0.000123611f /* ty=float32 */, 0 /* ty=int32 */, 0.0503514f /* ty=float32 */, 155 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %44 = qnn.dequantize(%43, 0.0503514f /* ty=float32 */, 155 /* ty=int32 */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %45 = qnn.dequantize(%37, 0.0339082f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %46 = add(%44, %45) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %47 = qnn.quantize(%46, 0.028905f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 128, 28, 28), uint8] */;\n",
      "  %48 = qnn.conv2d(%47, meta[relay.Constant][20] /* ty=Tensor[(256, 128, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.028905f /* ty=float32 */, 0.00185604f /* ty=float32 */, strides=[2, 2], padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %49 = nn.bias_add(%48, meta[relay.Constant][21] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %50 = qnn.requantize(%49, 5.3649e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0147711f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %51 = qnn.conv2d(%50, meta[relay.Constant][22] /* ty=Tensor[(256, 256, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0147711f /* ty=float32 */, 0.00444031f /* ty=float32 */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %52 = nn.bias_add(%51, meta[relay.Constant][23] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %53 = qnn.requantize(%52, 6.55884e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.04072f /* ty=float32 */, 102 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %54 = qnn.conv2d(%47, meta[relay.Constant][24] /* ty=Tensor[(256, 128, 1, 1), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.028905f /* ty=float32 */, 0.00321387f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %55 = nn.bias_add(%54, meta[relay.Constant][25] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %56 = qnn.requantize(%55, 9.2897e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0160918f /* ty=float32 */, 156 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %57 = qnn.dequantize(%53, 0.04072f /* ty=float32 */, 102 /* ty=int32 */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %58 = qnn.dequantize(%56, 0.0160918f /* ty=float32 */, 156 /* ty=int32 */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %59 = add(%57, %58) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %60 = qnn.quantize(%59, 0.0217659f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %61 = qnn.conv2d(%60, meta[relay.Constant][26] /* ty=Tensor[(256, 256, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0217659f /* ty=float32 */, 0.00214475f /* ty=float32 */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %62 = nn.bias_add(%61, meta[relay.Constant][27] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %63 = qnn.requantize(%62, 4.66825e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0174921f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %64 = qnn.conv2d(%63, meta[relay.Constant][28] /* ty=Tensor[(256, 256, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0174921f /* ty=float32 */, 0.00763875f /* ty=float32 */, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %65 = nn.bias_add(%64, meta[relay.Constant][29] /* ty=Tensor[(256), int32] */) /* ty=Tensor[(1, 256, 14, 14), int32] */;\n",
      "  %66 = qnn.requantize(%65, 0.000133618f /* ty=float32 */, 0 /* ty=int32 */, 0.0529469f /* ty=float32 */, 164 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %67 = qnn.dequantize(%66, 0.0529469f /* ty=float32 */, 164 /* ty=int32 */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %68 = qnn.dequantize(%60, 0.0217659f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %69 = add(%67, %68) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %70 = qnn.quantize(%69, 0.0367017f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 256, 14, 14), uint8] */;\n",
      "  %71 = qnn.conv2d(%70, meta[relay.Constant][30] /* ty=Tensor[(512, 256, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0367017f /* ty=float32 */, 0.00237498f /* ty=float32 */, strides=[2, 2], padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %72 = nn.bias_add(%71, meta[relay.Constant][31] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %73 = qnn.requantize(%72, 8.71658e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0136074f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %74 = qnn.conv2d(%73, meta[relay.Constant][32] /* ty=Tensor[(512, 512, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0136074f /* ty=float32 */, 0.0090061f /* ty=float32 */, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %75 = nn.bias_add(%74, meta[relay.Constant][33] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %76 = qnn.requantize(%75, 0.00012255f /* ty=float32 */, 0 /* ty=int32 */, 0.0484018f /* ty=float32 */, 114 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %77 = qnn.conv2d(%70, meta[relay.Constant][34] /* ty=Tensor[(512, 256, 1, 1), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0367017f /* ty=float32 */, 0.00785991f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %78 = nn.bias_add(%77, meta[relay.Constant][35] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %79 = qnn.requantize(%78, 0.000288472f /* ty=float32 */, 0 /* ty=int32 */, 0.0285382f /* ty=float32 */, 115 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %80 = qnn.dequantize(%76, 0.0484018f /* ty=float32 */, 114 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %81 = qnn.dequantize(%79, 0.0285382f /* ty=float32 */, 115 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %82 = add(%80, %81) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %83 = qnn.quantize(%82, 0.0334308f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %84 = qnn.conv2d(%83, meta[relay.Constant][36] /* ty=Tensor[(512, 512, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0334308f /* ty=float32 */, 0.00230916f /* ty=float32 */, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %85 = nn.bias_add(%84, meta[relay.Constant][37] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %86 = qnn.requantize(%85, 7.7197e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0133824f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %87 = qnn.conv2d(%86, meta[relay.Constant][38] /* ty=Tensor[(512, 512, 3, 3), int8] */, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.0133824f /* ty=float32 */, 0.0287268f /* ty=float32 */, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %88 = nn.bias_add(%87, meta[relay.Constant][39] /* ty=Tensor[(512), int32] */) /* ty=Tensor[(1, 512, 7, 7), int32] */;\n",
      "  %89 = qnn.requantize(%88, 0.000384433f /* ty=float32 */, 0 /* ty=int32 */, 0.225387f /* ty=float32 */, 68 /* ty=int32 */, axis=1, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %90 = qnn.dequantize(%89, 0.225387f /* ty=float32 */, 68 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %91 = qnn.dequantize(%83, 0.0334308f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %92 = add(%90, %91) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %93 = qnn.quantize(%92, 0.165314f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 7, 7), uint8] */;\n",
      "  %94 = qnn.dequantize(%93, 0.165314f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %95 = nn.global_avg_pool2d(%94) /* ty=Tensor[(1, 512, 1, 1), float32] */;\n",
      "  %96 = qnn.quantize(%95, 0.0553716f /* ty=float32 */, 0 /* ty=int32 */, out_dtype=\"uint8\") /* ty=Tensor[(1, 512, 1, 1), uint8] */;\n",
      "  %97 = qnn.dequantize(%96, 0.0553716f /* ty=float32 */, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(1, 512, 1, 1), float32] */;\n",
      "  %98 = nn.batch_flatten(%97) /* ty=Tensor[(1, 512), float32] */;\n",
      "  %99 = nn.dense(%98, meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */, units=1000) /* ty=Tensor[(1, 1000), float32] */;\n",
      "  add(%99, meta[relay.Constant][41] /* ty=Tensor[(1000), float32] */) /* ty=Tensor[(1, 1000), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "target = tvm.target.Target(tvm_target)\n",
    "\n",
    "with tvm.transform.PassContext(\n",
    "    opt_level=3,\n",
    "):\n",
    "    mod[\"main\"] = relay.build_module.bind_params_by_name(mod[\"main\"], params=params)\n",
    "    mod = relay.transform.InferType()(mod)\n",
    "    mod = relay.transform.SimplifyInference()(mod)\n",
    "    mod = relay.transform.FoldConstant(fold_qnn=True)(mod)\n",
    "    \n",
    "    print(mod)\n",
    "    \n",
    "    lib = relay.build(mod, target, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Test compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 03:26:46.101 INFO load_module /tmp/tmpnxvifpxu/net.tar\n",
      "[Test 100 img: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:34<00:00,  2.93it/s, Top1=tensor(67.), Top5=tensor(89.)]\n"
     ]
    }
   ],
   "source": [
    "import tvm_util\n",
    "\n",
    "dataset_tvm = torch_util.subset_dataset(dataset, dataset_samples_on_tvm, seed=dataset_seed)\n",
    "tvm_util.test_tvm(lib, dataset_tvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
